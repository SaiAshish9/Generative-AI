# Generative-AI

```
AI can be classified into two categpries:

1. GenAI

Generating new content like text, images, video, audio

for example ChatGPT


2. Non GenAI

We've data and based on that we are making certain decisions:

a. XRAY: A person has disease or not. 
b. Person should be given loan or not based on credit history data.


Evolution of GenAI:

Early days predicting home price

In the following pic:

Area, Bedrooms and Age are the simple features.

```

<img width="634" height="642" alt="Screenshot 2025-08-06 at 3 49 13 PM" src="https://github.com/user-attachments/assets/96df145a-8ede-44b1-9d64-c324e897d30e" />

```
Complex Features:
```

<img width="385" height="401" alt="Screenshot 2025-08-06 at 3 50 36 PM" src="https://github.com/user-attachments/assets/a6ae8b7f-197c-4f77-bd3b-e41b3d48f744" />


```
Hence, we can't simply use features for image detection hence therefore neural networks were invented and that had given birth to deep learning.
```

<img width="1020" height="668" alt="Screenshot 2025-08-06 at 4 02 52 PM" src="https://github.com/user-attachments/assets/fcac4484-d244-43ff-a8b7-08675387d6a4" />


<img width="916" height="318" alt="Screenshot 2025-08-06 at 4 03 32 PM" src="https://github.com/user-attachments/assets/53a18744-3cc8-4731-b910-31bf7c8a0bc4" />

```
After that came RNN
```

<img width="793" height="583" alt="Screenshot 2025-08-06 at 4 04 15 PM" src="https://github.com/user-attachments/assets/028d6948-7c37-4d49-894b-3f1b608a3f9f" />


```
RNN is used for solving problems like language translation where we provide words to the network.
An RNN (Recurrent Neural Network) is a type of neural network particularly well-suited for sequential data. Unlike traditional feedforward networks, 
RNNs have loops that allow information to persist, making them ideal for tasks involving time-series, text, audio, or any data where the order matters.
```

<img width="731" height="550" alt="Screenshot 2025-08-06 at 4 12 39 PM" src="https://github.com/user-attachments/assets/1ff5185b-70e7-495e-aa3e-aa94bc1bd48d" />

```
In Gmail it will try to autocomplete
```

<img width="679" height="548" alt="Screenshot 2025-08-06 at 4 13 13 PM" src="https://github.com/user-attachments/assets/0cf1a3ec-66e5-49f4-9c43-304d45b973d2" />


```
It looks at the content of the email. Network will read the sentence and predict the probability of the next word.
```

<img width="1110" height="230" alt="Screenshot 2025-08-06 at 4 16 01 PM" src="https://github.com/user-attachments/assets/d4bed52c-e45d-4cc8-85f5-e918654c761f" />
<img width="1120" height="312" alt="Screenshot 2025-08-06 at 5 53 49 PM" src="https://github.com/user-attachments/assets/67aa20e1-cfcb-40c7-b9c7-1fa540fcc551" />
<img width="1001" height="398" alt="Screenshot 2025-08-06 at 5 54 26 PM" src="https://github.com/user-attachments/assets/7e877651-fed1-4b34-95e2-fc515719b0ab" />

```
Reaching out has higher probability
```

```
Language Model is an AI model that can predict the next word (or set of worcs) for a given sequence of words
```

<img width="987" height="597" alt="Screenshot 2025-08-06 at 6 03 41 PM" src="https://github.com/user-attachments/assets/45083f3c-4e53-402e-8b5c-65dd4797841d" />


```
This approach of giving words to neural network is called self supervised learning.

We can generate these training pairs from variety of books
```

<img width="940" height="629" alt="Screenshot 2025-08-06 at 6 08 11 PM" src="https://github.com/user-attachments/assets/09c773f7-bd09-4a35-bcc9-71ad554ea591" />

```
When we feed huge amount of data and the neural network is big, we'll get large language model (LLM)
```

<img width="982" height="650" alt="Screenshot 2025-08-06 at 6 15 44 PM" src="https://github.com/user-attachments/assets/50997142-c1b2-4de4-8787-9d095d4275bd" />

```
GPT-4, the model behind chatgpt is an LLM.
```

<img width="801" height="619" alt="Screenshot 2025-08-06 at 6 17 49 PM" src="https://github.com/user-attachments/assets/a202cf7c-dbf6-442b-80e8-88afd64f825a" />

<img width="1162" height="664" alt="Screenshot 2025-08-06 at 6 19 53 PM" src="https://github.com/user-attachments/assets/dc3d4ca6-d051-43eb-8875-9018a77cc568" />

<img width="1030" height="660" alt="Screenshot 2025-08-06 at 6 20 21 PM" src="https://github.com/user-attachments/assets/d4b33b3f-11a3-41ac-83a9-f6b3dcc83ebe" />

<img width="1201" height="655" alt="Screenshot 2025-08-06 at 6 21 13 PM" src="https://github.com/user-attachments/assets/a3aa3516-bc9a-4d1d-8260-28e5c6fac07b" />

<img width="464" height="525" alt="Screenshot 2025-08-06 at 6 38 21 PM" src="https://github.com/user-attachments/assets/a6306ac5-6d66-4eb7-a516-2e29c233e00c" />

```
Google - BERT

BERT (Bidirectional Encoder Representations from Transformers) is a groundbreaking language model developed by Google AI in 2018.
It's designed to understand the context of words in a sentence more deeply than previous models, thanks to its bidirectional nature.

OpenAI - GPT
```

<img width="691" height="364" alt="Screenshot 2025-08-06 at 6 42 08 PM" src="https://github.com/user-attachments/assets/019473ea-b1bb-4df5-ace0-bca3481712ad" />
<img width="787" height="508" alt="Screenshot 2025-08-06 at 6 43 31 PM" src="https://github.com/user-attachments/assets/2635298b-7f32-4349-a53e-4ccebd778f21" />

```
Text Models: BERT (Google) and GPT (OpenAI)
```

```
Image Models: DALL-E and Stable Diffusion
```

<img width="1100" height="650" alt="Screenshot 2025-08-06 at 6 45 58 PM" src="https://github.com/user-attachments/assets/90d9df22-c350-4e40-a0da-3ead8b20a308" />
<img width="1232" height="657" alt="Screenshot 2025-08-06 at 6 46 27 PM" src="https://github.com/user-attachments/assets/a1d2f138-657e-4074-a78b-65263e42a578" />
<img width="912" height="558" alt="Screenshot 2025-08-06 at 6 57 33 PM" src="https://github.com/user-attachments/assets/b752a87b-0242-4331-89e9-edd360d55517" />
<img width="575" height="362" alt="Screenshot 2025-08-06 at 7 32 20 PM" src="https://github.com/user-attachments/assets/6d5e07ee-b308-4a25-9f9e-95a89a5677fb" />
<img width="828" height="492" alt="Screenshot 2025-08-06 at 7 33 38 PM" src="https://github.com/user-attachments/assets/fd73cfe0-67f3-42f5-9a88-40c51d9a9ea3" />
<img width="980" height="547" alt="Screenshot 2025-08-06 at 7 42 09 PM" src="https://github.com/user-attachments/assets/b00a6b40-2220-4689-9e96-c383e86707a4" />
<img width="1105" height="542" alt="Screenshot 2025-08-06 at 7 44 52 PM" src="https://github.com/user-attachments/assets/a5570143-ff35-41a1-b35f-0741e22a9f50" />
<img width="1104" height="536" alt="Screenshot 2025-08-06 at 7 47 28 PM" src="https://github.com/user-attachments/assets/51133ab9-fc61-4a10-8e37-cf8f0bd48593" />

```
Gmail uses language model underneath.
```

```
Parrot is predicting next word based on past conversations.
```

<img width="851" height="466" alt="Screenshot 2025-08-06 at 7 57 05 PM" src="https://github.com/user-attachments/assets/c2e8edc3-6a8f-4fbc-86e3-510be091f0ba" />
<img width="1193" height="484" alt="Screenshot 2025-08-06 at 8 00 29 PM" src="https://github.com/user-attachments/assets/1ec51fa9-9436-4b4d-bc1b-4f17e26039f6" />

```
LLM examples PaLM2 by Google and LLaMA by Meta:
```

<img width="1203" height="422" alt="Screenshot 2025-08-06 at 8 03 28 PM" src="https://github.com/user-attachments/assets/10cc7fac-56c3-46fe-9a46-6e055e63290a" />

```
LLM uses another approach called reinforcement learning with human feedback.
```

<img width="1228" height="535" alt="Screenshot 2025-08-06 at 8 07 42 PM" src="https://github.com/user-attachments/assets/6ba41d8f-b77e-4142-9389-9149b1cb8908" />

<img width="821" height="527" alt="Screenshot 2025-08-06 at 8 10 51 PM" src="https://github.com/user-attachments/assets/67c0e604-5516-4df9-8658-eb511604d4e7" />

<img width="1284" height="555" alt="Screenshot 2025-08-06 at 8 11 42 PM" src="https://github.com/user-attachments/assets/c177c543-8022-4ee1-89c1-50f376757a6c" />

```
For training openAI used a similar approach called human intervention

RLHF

Reinforcement learning with human feedback.

LLMs work purely on the data
```

```
Embeddings And Vector Data
```

```
Vector data allows us to store the embeddings
```

```
Semantic search means not searching using the exact keyword matching. But understanding the intent of a user query.
Using the context to perform the search.
Semantic search internally uses the concept of embedding. Numerical representation of text.
```

```
üîπ What Are Embeddings?

Embeddings are numerical representations of complex data (like text, images, audio, etc.) in a high-dimensional vector space.
They allow machines to understand the relationships and similarities between different pieces of data.
Think of embeddings as turning something like a word or sentence into a list of numbers (a vector) that captures its semantic meaning.

üîπ What Is Vector Data?

Vector data simply refers to this list of numbers (the output of embeddings). It's usually a floating-point array, like:
[0.13, -0.98, 0.56, ..., 0.24]  ‚Üê  (typically 128, 256, 512, or 768+ dimensions)

These vectors are then used for:
Similarity search
Clustering
Recommendation engines
Anomaly detection
Semantic search

üîπ Example Use Case: Text Embeddings
Let‚Äôs say you have two sentences:
‚ÄúI love pizza.‚Äù
‚ÄúPizza is amazing.‚Äù

After generating embeddings using a model like OpenAI‚Äôs text-embedding-3-small, their vectors might look like this:

Sentence A ‚Üí [0.11, -0.23, 0.99, ...]
Sentence B ‚Üí [0.12, -0.25, 1.01, ...]

You can then calculate the cosine similarity between these vectors to determine that they're semantically close.

üîπ Common Models to Generate Embeddings

OpenAI Embedding Models (e.g., text-embedding-3-small)
BERT / SBERT (Sentence-BERT)
CLIP (for image and text)
FastText, Word2Vec, GloVe (older models)

üîπ Tools to Store/Search Vector Data
Once you have embeddings, you can store them in vector databases:

FAISS (Facebook AI Similarity Search)
Pinecone
Weaviate
Qdrant
Milvus

These allow for efficient nearest neighbor search across millions of vectors.

Summary

Term	Description
Embedding	A numerical representation of data
Vector	The actual list of numbers (embedding result)
Vector DB	Specialized database to store and query vectors
Use Cases	Semantic search, recommendations, classification, etc.
```

<img width="950" height="606" alt="Screenshot 2025-08-07 at 12 10 06 AM" src="https://github.com/user-attachments/assets/59263421-3947-404c-95b1-c919713de6ea" />
<img width="978" height="584" alt="Screenshot 2025-08-07 at 12 17 29 AM" src="https://github.com/user-attachments/assets/9466a47e-0da7-462a-8344-e744381d0bc2" />
<img width="912" height="640" alt="Screenshot 2025-08-07 at 12 29 21 AM" src="https://github.com/user-attachments/assets/20d47975-93f6-476b-95c5-52b554b022cc" />
<img width="977" height="386" alt="Screenshot 2025-08-07 at 12 31 52 AM" src="https://github.com/user-attachments/assets/baef0c3a-978b-47f1-9dcf-d14021441392" />

<img width="1029" height="624" alt="Screenshot 2025-08-07 at 12 33 20 AM" src="https://github.com/user-attachments/assets/d7681c5b-61b6-4cc9-9e44-e7e30a79303b" />
<img width="1046" height="496" alt="Screenshot 2025-08-07 at 12 33 40 AM" src="https://github.com/user-attachments/assets/b4b4859f-d99c-4941-bb5a-dec9c0d566c5" />


```
Store Vectors
```

<img width="871" height="602" alt="Screenshot 2025-08-07 at 12 36 29 AM" src="https://github.com/user-attachments/assets/f468882b-6535-465a-9ef3-3aba220fbe36" />
<img width="1295" height="599" alt="Screenshot 2025-08-07 at 12 36 49 AM" src="https://github.com/user-attachments/assets/bfd23d52-c63a-4440-9e5f-d57b779ef100" />

```
Traditional RDS: MYSQL
```

<img width="1243" height="471" alt="Screenshot 2025-08-07 at 12 37 07 AM" src="https://github.com/user-attachments/assets/562a2e2b-4ae7-4c29-ba08-cb30163b0015" />
<img width="1253" height="579" alt="Screenshot 2025-08-07 at 12 37 33 AM" src="https://github.com/user-attachments/assets/8ed87954-c99c-48bb-b608-9ca5971aacfe" />
<img width="1265" height="388" alt="Screenshot 2025-08-07 at 12 38 01 AM" src="https://github.com/user-attachments/assets/8e66dea9-4e3d-49c8-83ca-14142cd77d1c" />
<img width="1049" height="624" alt="Screenshot 2025-08-07 at 12 38 33 AM" src="https://github.com/user-attachments/assets/dbbac369-ddab-4a06-9d19-03e63905d510" />
<img width="729" height="551" alt="Screenshot 2025-08-07 at 12 43 00 AM" src="https://github.com/user-attachments/assets/9eb35987-f6b2-4648-932b-4c7a5c35a906" />
<img width="943" height="672" alt="Screenshot 2025-08-07 at 12 43 22 AM" src="https://github.com/user-attachments/assets/d0c52b11-773d-4570-aa91-b79ee6107130" />

```
Database index helps you search things faster.
```

```

```

<img width="1005" height="487" alt="Screenshot 2025-08-07 at 10 10 09 AM" src="https://github.com/user-attachments/assets/0e939158-aa4e-48f4-836a-c8209d2a5f85" />
<img width="997" height="471" alt="Screenshot 2025-08-07 at 10 16 08 AM" src="https://github.com/user-attachments/assets/7247633e-95f4-49b5-ba4d-d7af57451531" />

```
Hashing function allows us to only match in the desired bucket and not all the buckets. This is known as locality sensitive hashing. There are more search techniques.
```
https://www.pinecone.io/learn/vector-database/

<img width="722" height="502" alt="Screenshot 2025-08-07 at 10 16 58 AM" src="https://github.com/user-attachments/assets/185e91db-41a8-4397-88c9-795e0901ae7e" />


```
Benefits of vector database:

1. Fast Search
2. Optimized storage
```

<img width="927" height="436" alt="Screenshot 2025-08-07 at 10 20 00 AM" src="https://github.com/user-attachments/assets/b93fb5f9-1783-4f25-baa8-ca7d7b48cb05" />



